[COMMON]
seed =  88

# 1. set dataset, model
# dataset: cord4lm, funsd4lm, docvqa, 
dataset_name = funsd4lm

network_type = layoutlm

#output_dir = layoutlmv3-cord

# 2. {docvqa, token-classifier, link-binary, node-classify, neib-regression, direct-classify; neib-regression}
# task_type = docvqa
task_type = token-classifier
# task_type = direct-classify
# task_type = neib-regression
# task_type = node-classify

# do not use {binary-label, multi-label, regression }, because you need specific task preparation info.

# 3. set hyper parameters
batch_size = 6
epochs = 10
lr = 0.00001
patience = 10
dropout = 0.2
max_seq_len = 50

hidden_dim = 100
hidden_dim_1 = 64
hidden_dim_2 = 32

# 4. continue train
continue_train = False
continue_with_model = tmp_dir/layoutlm_cord_948065


# other less common parameters 
embedding_trainable = True

# FUNSD
funsd_train = ../data/FUNSD/training_data/
funsd_test =  ../data/FUNSD/testing_data/
layoutlm_dir = /home/ubuntu/resources/layoutlmv3.funsd

docvqa_dir = /home/ubuntu/resources/shared_efs/vrdu/datasets/docvqa
docvqa_train = /home/ubuntu/resources/shared_efs/vrdu/datasets/docvqa/val
docvqa_test = /home/ubuntu/resources/shared_efs/vrdu/datasets/docvqa/test



