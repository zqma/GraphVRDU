[COMMON]
seed =  88

# 1. set dataset, model
dataset_name = docvqa
embedding_trainable = True
network_type = layoutlm

max_seq_len = 50

output_dir = layoutlmv3-cord

# 2. {docvqa, token-classifier, link-binary, node-classify, neib-regression, direct-classify; neib-regression}
task_type = docvqa
# task_type = direct-classify
# task_type = neib-regression
# task_type = node-classify

# do not use {binary-label, multi-label, regression }, because you need specific task preparation info.

# 3. set hyper parameters
batch_size = 3
epochs = 3
lr = 0.01
patience = 10
dropout = 0.1


hidden_dim = 100
hidden_dim_1 = 64
hidden_dim_2 = 32

# 4. continue train
continue_train = False
continue_with_model = tmp_dir/layoutlm_cord_948065

# FUNSD
funsd_train = ../data/FUNSD/training_data/
funsd_test =  ../data/FUNSD/testing_data/
layoutlm_dir = /home/ubuntu/resources/layoutlmv3.base

docvqa_dir = /home/ubuntu/resources/shared_efs/vrdu/datasets/docvqa
docvqa_train = /home/ubuntu/resources/shared_efs/vrdu/datasets/docvqa/val
docvqa_test = /home/ubuntu/resources/shared_efs/vrdu/datasets/docvqa/test



